
# ğŸ“„Text Summarizer using Local LLM

A lightweight, local-first application that summarizes `.txt` or `.pdf` files using **Metaâ€™s LLaMA 3 model** running through **Ollama**, orchestrated via **LangChain**, and wrapped in an elegant **Streamlit UI**.

This app runs entirely on your machine â€” no API keys required, no cloud dependencies.

---

## ğŸš€ Features

-   âœ… Upload `.txt` or `.pdf` files.
-   ğŸ§  Summarize with **LLaMA 3** running locally via `ollama`.
-   ğŸ—‚ï¸ View full raw content inside an expandable preview.
-   âœï¸ Output summaries styled for different audiences: `Professor`, `Student`, `Novice`.
-   ğŸ’¾ Download summaries as `.txt` files.
-   âš¡ Runs offline after the LLaMA 3 model is pulled.

---

## ğŸ–¥ï¸ Demo Screenshot

![App Screenshot](./screenshots/app_demo.jpg)

---

## ğŸ› ï¸ Tech Stack

| Component    | Usage                                  |
| :----------- | :------------------------------------- |
| ğŸ¦™ Ollama     | Runs the LLaMA 3 model locally.        |
| ğŸ§© LangChain  | Handles prompt management and chaining. |
| ğŸ§ª Streamlit  | Provides the UI for uploading & interaction. |
| ğŸ“„ pdfplumber | Extracts text from PDF files.          |
| ğŸ Python     | The base programming language.         |

---

## ğŸ“¦ Installation

Follow these steps to get the LLaMA 3 Text Summarizer up and running on your machine.

### 1. Clone the repository

```bash
git clone [https://github.com/Harish9215/AI_Summary.git](https://github.com/Harish9215/AI_Summary.git)
cd AI_Summary
````

### 2\. Set up a virtual environment

It's recommended to use a virtual environment to manage dependencies.

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: `venv\Scripts\activate`
```

### 3\. Install dependencies

Install the required Python libraries using pip.

```bash
pip install -r requirements.txt
```

### 4\. Run Ollama & pull LLaMA model

You'll need to have Ollama installed on your system. If you don't have it, follow the instructions on the [Ollama website](https://ollama.com/download).

Once Ollama is installed, pull the LLaMA 3 model:

```bash
ollama pull llama3
ollama serve # This command is optional; Ollama typically runs in the background.
```

-----

## â–¶ï¸ Run the App

After completing the installation steps, launch the Streamlit app:

```bash
streamlit run app.py
```

-----

## ğŸ“ Project Structure

```
AI_Summary/
â”œâ”€â”€ app.py              # Streamlit frontend for the UI
â”œâ”€â”€ summary.py          # LangChain prompt and summarization logic
â”œâ”€â”€ requirements.txt    # Python dependencies for the project
â”œâ”€â”€ .gitignore          # Specifies intentionally untracked files to ignore
â”œâ”€â”€ README.md           # This README file
â””â”€â”€ screenshots/        # (Optional) Folder for app screenshots
```

-----

## ğŸ‘¤ Audience Modes

The app allows you to tailor the summary's style for different audiences:

  * **Professor**: Technical and formal, suitable for academic or expert audiences.
  * **Student**: Academic but accessible, ideal for college or university students.
  * **Novice**: Simple, friendly, and jargon-free, perfect for beginners or general audiences.

-----

## ğŸ“Œ Example Use Cases

  * ğŸ“š Summarize research papers quickly.
  * ğŸ“ Create concise executive summaries of lengthy documents.
  * ğŸ“„ Convert raw notes into readable, organized insights.
  * ğŸ§‘â€ğŸ« Explain complex technical PDFs to beginners in an understandable way.

-----

## ğŸ§  LLaMA 3 Model

The core of this application is Meta's LLaMA 3 model. It runs entirely locally through Ollama, ensuring no API keys are required and your data remains private. By default, it uses the LLaMA 3 8B model, though it can be configured for the 3.2B version if preferred.

-----

## ğŸ™Œ Acknowledgments

Special thanks to:

  * **Meta AI** for developing the powerful LLaMA 3 model.
  * **LangChain** for simplifying model orchestration and prompt management.
  * **Ollama** for making local LLM inference incredibly easy.
  * **Streamlit** for enabling the creation of beautiful, interactive web apps with Python.

-----

## âœ¨ Author

Made with â¤ï¸ by [Harish Mohan](https://www.google.com/search?q=https://github.com/Harish9215)

```
```